######################################################
#Por la fecha, el scraping se hizo siguiendo esta p??gina: https://datanalytics.com/libro_r/web-scraping.html
# 00. Data Acquisition #
#Cargamos los paquetes necesarios----------------------
install.packages("rvest")
library(rvest) # Para scraping
library(pacman)
p_load(rio) # Librer??a para importar datos
p_load(tidyverse) # Librer??a para limpiar datos
p_load(e1071) # Tiene la funci??n para calcular skewness
p_load(EnvStats) # Transformaci??n Box-Cox
p_load(tidymodels) # Modelos ML
p_load(ggplot2) # Librer??a para visualizar datos
p_load(scales) # Formato de los ejes en las gr??ficas
p_load(ggpubr) # Combinar gr??ficas
p_load(knitr) # Tablas dentro de Rmarkdown
p_load(kableExtra) # Tablas dentro de Rmarkdown
p_load(rvest)
#Cargamos los paquetes necesarios----------------------
install.packages("rvest")
install.packages("dplyr")
library(dplyr)
library(rvest) # Para scraping
library(pacman)
library(tidyverse)
p_load(rio) # Librer??a para importar datos
p_load(tidyverse) # Librer??a para limpiar datos
p_load(e1071) # Tiene la funci??n para calcular skewness
p_load(EnvStats) # Transformaci??n Box-Cox
p_load(tidymodels) # Modelos ML
p_load(ggplot2) # Librer??a para visualizar datos
p_load(scales) # Formato de los ejes en las gr??ficas
p_load(ggpubr) # Combinar gr??ficas
p_load(knitr) # Tablas dentro de Rmarkdown
p_load(kableExtra) # Tablas dentro de Rmarkdown
p_load(rvest)
#Limpiamos todo pos si las moscas ---------------------
rm(list = ls())
#cargamos el url--------------------------------------
url_scraping <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
geih <- data.frame()
url <- paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html")
temp <- read_html(url) %>%
html_table()
geih <- rbin(geih, temp)
geih <- data.frame()
for (i in 1:2){
temp <- read_html(paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_",i,".html"))%>%
html_table()
geih <- temp
rbind(geih)
}
summary(geih)
#Cargamos los paquetes necesarios----------------------
p_load(rio) # Librer??a para importar datos
p_load(tidyverse) # Librer??a para limpiar datos
p_load(e1071) # Tiene la funci??n para calcular skewness
p_load(EnvStats) # Transformaci??n Box-Cox
p_load(tidymodels) # Modelos ML
p_load(ggplot2) # Librer??a para visualizar datos
p_load(scales) # Formato de los ejes en las gr??ficas
p_load(ggpubr) # Combinar gr??ficas
p_load(knitr) # Tablas dentro de Rmarkdown
p_load(kableExtra) # Tablas dentro de Rmarkdown
p_load(rvest)
p_load(pacman)
p_load(dplyr)
#Cargamos los paquetes necesarios----------------------
library(rio) # Librer??a para importar datos
library(tidyverse) # Librer??a para limpiar datos
#Cargamos los paquetes necesarios----------------------
library(rio)
library(tidyverse) # Librer??a para limpiar datos
#Cargamos los paquetes necesarios----------------------
library(rio)
library(tidyverse)
library(e1071)
library(EnvStats)
library(tidymodels)
library(ggplot2)
library(scales)
library(ggpubr)
library(knitr)
library(kableExtra)
library(rvest)
library(pacman)
library(dplyr)
# Authors: Pablo Cerezo Lesmes & Juan Sebasti??n Dur??n Dur??n
######################################################
#Por la fecha, el scraping se hizo siguiendo esta p??gina: https://datanalytics.com/libro_r/web-scraping.html
# 02. Data cleanning #
rm(list = ls())
#Cargamos la data--------------------------------------
geih <- data.frame()
url <- paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html")
temp <- read_html(url) %>%
html_table()
geih <- rbin(geih, temp)
# Authors: Pablo Cerezo Lesmes & Juan Sebasti??n Dur??n Dur??n
######################################################
#Por la fecha, el scraping se hizo siguiendo esta p??gina: https://datanalytics.com/libro_r/web-scraping.html
# 02. Data cleanning #
rm(list = ls())
#Cargamos los paquetes necesarios----------------------
library(rio)
library(tidyverse)
library(e1071)
library(EnvStats)
library(tidymodels)
library(ggplot2)
library(scales)
library(ggpubr)
library(knitr)
library(kableExtra)
library(rvest)
library(pacman)
library(dplyr)
#Cargamos la data--------------------------------------
geih <- data.frame()
url <- paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_", i,".html")
temp <- read_html(url) %>%
html_table()
#Cargamos la data--------------------------------------
geih <- data.frame()
temp <- read_html(paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_",i,".html"))%>%
html_table()
#Cargamos la data--------------------------------------
geih <- data.frame()
temp <- read_html(paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html"))%>%
html_table()
geih <- temp
#Cargamos la data--------------------------------------
geih <- data.frame()
temp <- read_html(paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html"))%>%
html_table(temp)
geih <- temp
# Authors: Pablo Cerezo Lesmes & Juan Sebasti??n Dur??n Dur??n
######################################################
#Por la fecha, el scraping se hizo siguiendo esta p??gina: https://datanalytics.com/libro_r/web-scraping.html
# 02. Data cleanning #
rm(list = ls())
#Cargamos los paquetes necesarios----------------------
library(rio)
library(tidyverse)
library(e1071)
library(EnvStats)
library(tidymodels)
library(ggplot2)
library(scales)
library(ggpubr)
library(knitr)
library(kableExtra)
library(rvest)
library(pacman)
library(dplyr)
#Cargamos la data--------------------------------------
geih <- data.frame()
temp <- read_html(paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html"))%>%
html_table(temp)
geih <- temp
# Authors: Pablo Cerezo Lesmes & Juan Sebasti??n Dur??n Dur??n
######################################################
#Por la fecha, el scraping se hizo siguiendo esta p??gina: https://datanalytics.com/libro_r/web-scraping.html
# 02. Data cleanning #
rm(list = ls())
#Cargamos los paquetes necesarios----------------------
library(rio)
library(tidyverse)
library(e1071)
library(EnvStats)
library(tidymodels)
library(ggplot2)
library(scales)
library(ggpubr)
library(knitr)
library(kableExtra)
library(rvest)
library(pacman)
library(dplyr)
#Cargamos la data--------------------------------------
geih <- data.frame()
temp <- read_html(paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html"))%>%
html_table()
geih <- temp
View(geih)
View(geih)
# Authors: Pablo Cerezo Lesmes & Juan Sebasti??n Dur??n Dur??n
######################################################
#Por la fecha, el scraping se hizo siguiendo esta p??gina: https://datanalytics.com/libro_r/web-scraping.html
# 02. Data cleanning #
rm(list = ls())
#Cargamos la data--------------------------------------
geih <- data.frame()
geih <- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html")%>%
html_table()
View(geih)
View(geih)
x=1
"https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_",x,".html"
"https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_", x ,".html"
"https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"x".html"
"https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_',x,'.html"
"https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_" ,x, ".html"
"https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_", x ,".html"
url <-paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_x.html")
"https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"x".html"
"https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_", x".html"
"https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_", x,".html"
"https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html"
"https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_", x ," .html"
"https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html"
geih <- data.frame()
for (x in 1:10){
url <-paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html")
temp <- read_html(url)%>%
html_table()
geih <- rbind(geih, Yemp)
}
# Authors: Pablo Cerezo Lesmes & Juan Sebasti??n Dur??n Dur??n
######################################################
#Por la fecha, el scraping se hizo siguiendo esta p??gina: https://datanalytics.com/libro_r/web-scraping.html
# 02. Data cleanning #
rm(list = ls())
#Cargamos la data--------------------------------------
geih <- data.frame()
url <-paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html")
temp <- read_html(url)%>%
html_table()
geih <- temp
View(geih)
View(geih)
GEIH <- as.data.frame(geih)
View(GEIH)
View(GEIH)
View(GEIH)
View(GEIH)
#2.1 Variables de interés------------------------------
#Dejamos mayores de edad
GEIH_adultos<-GEIH[!(GEIH$age>=18)]
GEIH_adultos
#2.1 Variables de interés------------------------------
#Dejamos mayores de edad
GEIH_adultos<-GEIH[!(GEIH$ age>=18)]
#2.1 Variables de interés------------------------------
#Dejamos mayores de edad
GEIH_adultos<-GEIH[(GEIH$age>=18)]
#2.1 Variables de interés------------------------------
#Dejamos mayores de edad
GEIH_adultos<-GEIH[($age>=18)]
#2.1 Variables de interés------------------------------
#Dejamos mayores de edad
GEIH_adultos<-data.frame()
GEIH_adultos<-GEIH[(GEIH$age>=18)]
GEIH_adultos<-GEIH[!(GEIH$age>=18)]
GEIH_adultos<-GEIH[!(GEIH$age>=18),]
GEIH_adultos
# Authors: Pablo Cerezo Lesmes & Juan Sebasti??n Dur??n Dur??n
######################################################
#Por la fecha, el scraping se hizo siguiendo esta p??gina: https://datanalytics.com/libro_r/web-scraping.html
# 02. Data cleanning #
rm(list = ls())
url <-paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html")
temp <- read_html(url)%>%
html_table()
geih <- temp
GEIH <- as.data.frame(geih)
GEIH_adultos<-data.frame()
GEIH_adultos<-GEIH[!(GEIH$age>=18) | (GEIH$ocu==1),]
View(GEIH_adultos)
GEIH_adultos<-GEIH[!(GEIH$age>=18),]
#2.1 Variables de interés------------------------------
#Dejamos mayores de edad y trabajadores
GEIH_adultos<-data.frame()
GEIH_adultos<-GEIH[!(GEIH$age>=18| GEIH$ocu==1),]
View(GEIH_adultos)
View(GEIH_adultos)
#2.1 Variables de interés------------------------------
#Dejamos mayores de edad y trabajadores
GEIH_adultos<-data.frame()
GEIH_adultos<-GEIH[!(GEIH$age<18| GEIH$ocu=!1),]
# Authors: Pablo Cerezo Lesmes & Juan Sebasti??n Dur??n Dur??n
######################################################
#Por la fecha, el scraping se hizo siguiendo esta p??gina: https://datanalytics.com/libro_r/web-scraping.html
# 02. Data cleanning #
rm(list = ls())
url <-paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html")
temp <- read_html(url)%>%
html_table()
geih <- temp
GEIH <- as.data.frame(geih)
GEIH_adultos<-data.frame()
GEIH_adultos<-subset(GEIH, age>=18 & ocu==1)
View(GEIH_adultos)
View(GEIH_adultos)
######################################################
#Problem Set 1: Predicting Income#
# Authors: Pablo Cerezo Lesmes & Juan Sebasti??n Dur??n Dur??n
######################################################
#Por la fecha, el scraping se hizo siguiendo esta p??gina: https://datanalytics.com/libro_r/web-scraping.html
# 02. Data cleanning #
rm(list = ls())
#Cargamos los paquetes necesarios----------------------
library(rio)
library(tidyverse)
library(e1071)
library(EnvStats)
library(tidymodels)
library(ggplot2)
library(scales)
library(ggpubr)
library(knitr)
library(kableExtra)
library(rvest)
library(pacman)
library(dplyr)
#Cargamos la data--------------------------------------
geih <- data.frame()
for (x in 1:10){
url <-paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html")
temp <- read_html(url)%>%
html_table()
geih <- temp
GEIH <- as.data.frame(geih)
}
geih <- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html")%>%
html_table()
#2.1 Variables de interés------------------------------
#Dejamos mayores de edad y trabajadores
GEIH_ocupados<-data.frame()
GEIH_ocupados<-subset(GEIH, age>=18 & ocu==1)
GEIH_ocupados <- GEIH_ocupados %>%
mutate(edad2 =edad^2)
GEIH_ocupados <- GEIH_ocupados %>%
mutate(age2 =age^2)
View(GEIH_ocupados)
View(GEIH_ocupados)
GEIH_punto3 <- subset(GEIH_ocupados, select = c (age, age2))
GEIH_ocupados <- GEIH_ocupados %>%
mutate(age2 =age^2,
age_sex =age*sex,
age_sex2 = age2*sex)
GEIH_punto4 <- subset(GEIH_ocupados, select = c (sex, ingtot, age, age2,
age_sex, age_sex2, relab,
maxEducLevel))
View(GEIH)
View(GEIH)
rm(list = ls())
#Cargamos los paquetes necesarios----------------------
library(tidyverse)
library(rvest)
library(pacman)
library(dplyr)
library(readr, warn.conflicts = FALSE)
#Cargamos la data--------------------------------------
GEIH <- data.frame()
for (i in 1:10){
url <-paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_",i,".html")
temp <- read_html(url)%>%
html_table()
temp <- as.data.frame(temp)
GEIH <- rbind(GEIH,temp)
}
GEIH_ocupados<-data.frame()
GEIH_ocupados<-subset(GEIH, age>=18 & ocu==1)
GEIH_ocupados <- GEIH_ocupados %>%
mutate(age2 = age^2,
age_sex = age*sex,
age_sex2 = age2*sex,
ln_Ing = ln(ingtot),
formal_sex = formal*sex,
realb_sex = relab*sex,
)
GEIH_ocupados <- GEIH_ocupados %>%
mutate(age2 = age^2,
age_sex = age*sex,
age_sex2 = age2*sex,
log_Ing = log(ingtot),
formal_sex = formal*sex,
realb_sex = relab*sex,
)
GEIH_clean <- subset(GEIH_ocupados, select = c (sex, ingtot, age, age2,
age_sex, age_sex2, formal,
relab,maxEducLevel, depto,
clase, p6426, ln_Ing, formal_sex,
realb_sex))
GEIH_clean <- subset(GEIH_ocupados, select = c (sex, ingtot, age, age2,
age_sex, age_sex2, formal,
relab,maxEducLevel, depto,
clase, p6426, log_Ing, formal_sex,
realb_sex))
#Creamos años de educación según máximo nivel educativo alcanzado
GEIH_clean <- GEIH_clean %>%
mutate(años_educ=0
)
View(GEIH_clean)
GEIH_clean<- replace(GEIH_clean$años_educ, GEIH_clean$maxEducLevel=3, 4)
GEIH_clean<- replace(GEIH_clean$años_educ, GEIH_clean$maxEducLevel==3, 4)
summary(año_educ)
GEIH_clean <- GEIH_clean %>%
mutate(años_educ=0)
GEIH_clean<- replace(GEIH_clean$años_educ, GEIH_clean$maxEducLevel==3, 4)
summary(años_educ)
GEIH_clean <- GEIH_clean %>%
mutate(años_educ=0)
GEIH_clean<- replace(GEIH_clean$años_educ, GEIH_clean$maxEducLevel==3, 4)
summary(años_educ)
View(GEIH_ocupados)
View(GEIH_ocupados)
GEIH_ocupados<-data.frame()
GEIH_ocupados<-subset(GEIH, age>=18 & ocu==1)
#Creamos interacciones de variables de interés
GEIH_ocupados <- GEIH_ocupados %>%
mutate(age2 = age^2,
age_sex = age*sex,
age_sex2 = age2*sex,
log_Ing = log(ingtot),
formal_sex = formal*sex,
realb_sex = relab*sex,
)
#Creamos el df con las variables de interés
GEIH_clean <- subset(GEIH_ocupados, select = c (sex, ingtot, age, age2,
age_sex, age_sex2, formal,
relab,maxEducLevel, depto,
clase, p6426, log_Ing, formal_sex,
realb_sex))
#Creamos años de educación según máximo nivel educativo alcanzado
GEIH_clean <- GEIH_clean %>%
mutate(años_educ=0)
GEIH_clean<- replace(GEIH_clean$años_educ, GEIH_clean$maxEducLevel==3, 4)
#fin limpieza de la base
GEIH_clean <- subset(GEIH_ocupados, select = c (sex, ingtot, age, age2,
age_sex, age_sex2, formal,
relab,maxEducLevel, depto,
clase, p6426, log_Ing, formal_sex,
realb_sex))
View(GEIH_clean)
#Creamos años de educación según máximo nivel educativo alcanzado
GEIH_clean <- GEIH_clean %>%
mutate(años_educ=0)
GEIH_clean<- replace(GEIH_clean$años_educ, GEIH_clean$maxEducLevel==3, 4)
summarise(GEIH_clean$años_educ)
summarise(años_educ)
max(años_educ)
GEIH_clean <- GEIH_clean %>%
mutate(años_educ=0)
GEIH_clean<- replace(GEIH_clean$años_educ, GEIH_clean$maxEducLevel==3, 4)
max(años_educ)
GEIH_clean <- subset(GEIH_ocupados, select = c (sex, ingtot, age, age2,
age_sex, age_sex2, formal,
relab,maxEducLevel, depto,
clase, p6426, log_Ing, formal_sex,
realb_sex))
#Creamos años de educación según máximo nivel educativo alcanzado
GEIH_clean <- GEIH_clean %>%
mutate(años_educ=0)
GEIH_clean<- replace(GEIH_clean$años_educ, GEIH_clean$maxEducLevel==3, 4)
max(años_educ)
GEIH_clean <- subset(GEIH_ocupados, select = c (sex, ingtot, age, age2,
age_sex, age_sex2, formal,
relab,maxEducLevel, depto,
clase, p6426, log_Ing, formal_sex,
realb_sex))
#Creamos años de educación según máximo nivel educativo alcanzado
GEIH_clean <- GEIH_clean %>%
mutate(años_educ=0)
GEIH_clean<- replace(GEIH_clean$años_educ, GEIH_clean$maxEducLevel==3, 4)
View(GEIH_ocupados)
rm(list = ls())
#Cargamos los pa
rm(list = ls())
#Cargamos los paquetes necesarios----------------------
library(tidyverse)
library(rvest)
library(pacman)
library(dplyr)
library(readr, warn.conflicts = FALSE)
#Cargamos la data--------------------------------------
GEIH <- data.frame()
for (i in 1:10){
url <-paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_",i,".html")
temp <- read_html(url)%>%
html_table()
temp <- as.data.frame(temp)
GEIH <- rbind(GEIH,temp)
}
#Fin del scraping
######################################################
# 2. Data cleaning #
####################################################
#2.1 Variables de interés------------------------------
#Dejamos mayores de edad y trabajadores
GEIH_ocupados<-data.frame()
GEIH_ocupados<-subset(GEIH, age>=18 & ocu==1)
#Creamos interacciones de variables de interés
GEIH_ocupados <- GEIH_ocupados %>%
mutate(age2 = age^2,
age_sex = age*sex,
age_sex2 = age2*sex,
log_Ing = log(ingtot),
formal_sex = formal*sex,
realb_sex = relab*sex,
)
#Creamos el df con las variables de interés
GEIH_clean <- subset(GEIH_ocupados, select = c (sex, ingtot, age, age2,
age_sex, age_sex2, formal,
relab,maxEducLevel, depto,
clase, p6426, log_Ing, formal_sex,
realb_sex))
#Creamos años de educación según máximo nivel educativo alcanzado
GEIH_clean <- GEIH_clean %>%
mutate(años_educ=0)
GEIH_clean<- replace(GEIH_clean$años_educ, GEIH_clean$maxEducLevel==3, 4)
